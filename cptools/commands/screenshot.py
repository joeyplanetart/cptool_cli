"""æˆªå±å‘½ä»¤å®ç°"""
import click
import asyncio
import csv
import random
import shutil
import webbrowser
from pathlib import Path
from urllib.parse import urlparse, urljoin
from datetime import datetime
from typing import List, Dict
import sys

from playwright.async_api import async_playwright, Browser
from cptools.utils.logger import setup_logger
from cptools.utils.html_report import generate_html_report
from cptools.utils.dingding import send_dingding_notification


@click.command()
@click.option(
    '--host', '-h', required=True,
    help='é»˜è®¤ä¸»æœºåœ°å€ï¼ˆå½“CSVä¸­çš„URLæ²¡æœ‰åŸŸåæ—¶ä½¿ç”¨ï¼‰')
@click.option(
    '--csv', 'csv_file', required=True, type=click.Path(exists=True),
    help='CSVæ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«è¦æˆªå›¾çš„URLåˆ—è¡¨')
@click.option(
    '--output', '-o', default='./screenshots',
    help='æˆªå›¾ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ï¼š./screenshotsï¼‰')
@click.option(
    '--log', '-l', default='',
    help='æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼š./logs/YYYYMMDD_HHMMSS.logï¼‰')
@click.option(
    '--html', default='./result.html',
    help='HTMLæŠ¥å‘Šè¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤ï¼š./result.htmlï¼‰')
@click.option(
    '--concurrency', '-c', default=5, type=int,
    help='å¹¶å‘æ•°é‡ï¼ˆé»˜è®¤ï¼š5ï¼‰')
@click.option(
    '--dingding-webhook',
    default='https://oapi.dingtalk.com/robot/send?access_token='
            'cc51fb8d186b18fd2ee82e24b0d5a810b11ba817de855b98fb3058f4c4e60767',
    help='é’‰é’‰æœºå™¨äººWebhook URLï¼ˆé»˜è®¤å·²é…ç½®ï¼‰')
@click.option(
    '--timeout', default=30000, type=int,
    help='é¡µé¢åŠ è½½è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼Œé»˜è®¤ï¼š30000ï¼‰')
@click.option(
    '--width', default=2560, type=int,
    help='æµè§ˆå™¨çª—å£å®½åº¦ï¼ˆé»˜è®¤ï¼š2560ï¼Œ2Kåˆ†è¾¨ç‡ï¼‰')
@click.option(
    '--height', default=1440, type=int,
    help='æµè§ˆå™¨çª—å£é«˜åº¦ï¼ˆé»˜è®¤ï¼š1440ï¼Œ2Kåˆ†è¾¨ç‡ï¼‰')
@click.option(
    '--template', default='default',
    type=click.Choice(['default', 'terminal', 'minimal']),
    help='HTMLæŠ¥å‘Šæ¨¡æ¿ï¼ˆé»˜è®¤ï¼šdefaultï¼‰')
def screenshot(host, csv_file, output, log, html, concurrency,
               dingding_webhook, timeout, width, height, template):
    """ç½‘é¡µæˆªå±å·¥å…·

    ä»CSVæ–‡ä»¶è¯»å–URLåˆ—è¡¨å¹¶è¿›è¡Œæˆªå›¾ã€‚CSVæ–‡ä»¶åº”åŒ…å«ä»¥ä¸‹åˆ—ï¼š

    \b
    - url: é¡µé¢URLï¼ˆå¯ä»¥æ˜¯å®Œæ•´URLæˆ–ç›¸å¯¹è·¯å¾„ï¼‰
    - name: æˆªå›¾åç§°ï¼ˆå¯é€‰ï¼Œç”¨äºæ ‡è¯†ï¼‰

    ç¤ºä¾‹ï¼š

    \b
    cptools screenshot -h http://www.cafepress.com \\
        --csv data.csv -l log.log --html result.html

    \b
    cptools screenshot --host http://example.com \\
        --csv urls.csv --output ./imgs -c 10
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥å¿—æ–‡ä»¶ï¼Œè‡ªåŠ¨ç”ŸæˆåŸºäºæ—¶é—´æˆ³çš„æ–‡ä»¶å
    if not log:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log = f'./logs/{timestamp}.log'
        # ç¡®ä¿ logs ç›®å½•å­˜åœ¨
        Path('./logs').mkdir(parents=True, exist_ok=True)

    # è®¾ç½®æ—¥å¿—
    logger = setup_logger(log)

    logger.info("=" * 80)
    logger.info("å¼€å§‹æ‰§è¡Œæˆªå±ä»»åŠ¡")
    logger.info(f"ä¸»æœºåœ°å€: {host}")
    logger.info(f"CSVæ–‡ä»¶: {csv_file}")
    logger.info(f"è¾“å‡ºç›®å½•: {output}")
    logger.info(f"å¹¶å‘æ•°: {concurrency}")
    logger.info(f"è¶…æ—¶æ—¶é—´: {timeout}ms")
    logger.info(f"çª—å£å¤§å°: {width}x{height}")
    logger.info(f"æŠ¥å‘Šæ¨¡æ¿: {template}")
    logger.info("=" * 80)

    # æ£€æŸ¥Playwrightæ˜¯å¦å·²å®‰è£…
    try:
        from playwright.async_api import async_playwright  # noqa: F401
    except ImportError:
        logger.error("Playwrightæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install playwright")
        logger.error("ç„¶åè¿è¡Œ: playwright install chromium")
        sys.exit(1)

    # è¯»å–CSVæ–‡ä»¶
    urls = read_csv_urls(csv_file, logger)
    if not urls:
        logger.error("CSVæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„URL")
        sys.exit(1)

    logger.info(f"ä»CSVæ–‡ä»¶ä¸­è¯»å–åˆ° {len(urls)} ä¸ªURL")

    # æ¸…ç†æ—§æ–‡ä»¶
    output_dir = Path(output)
    html_path = Path(html)

    # åˆ é™¤æ—§çš„æˆªå›¾ç›®å½•
    if output_dir.exists():
        logger.info(f"åˆ é™¤æ—§çš„æˆªå›¾ç›®å½•: {output_dir}")
        shutil.rmtree(output_dir)

    # åˆ é™¤æ—§çš„HTMLæŠ¥å‘Š
    if html_path.exists():
        logger.info(f"åˆ é™¤æ—§çš„HTMLæŠ¥å‘Š: {html_path}")
        html_path.unlink()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"åˆ›å»ºæ–°çš„æˆªå›¾ç›®å½•: {output_dir}")

    # æ‰§è¡Œæˆªå›¾ä»»åŠ¡
    start_time = datetime.now()
    results = asyncio.run(
        run_screenshot_tasks(
            urls=urls,
            host=host,
            output_dir=output_dir,
            concurrency=concurrency,
            timeout=timeout,
            width=width,
            height=height,
            logger=logger
        )
    )
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()

    # ç»Ÿè®¡ç»“æœ
    total = len(results)
    success = sum(1 for r in results if r.get('status') == 'success')
    failed = total - success

    logger.info("=" * 80)
    logger.info("æˆªå±ä»»åŠ¡å®Œæˆ")
    logger.info(f"æ€»æ•°: {total}")
    logger.info(f"æˆåŠŸ: {success}")
    logger.info(f"å¤±è´¥: {failed}")
    logger.info(f"è€—æ—¶: {duration:.2f}ç§’")
    logger.info("=" * 80)

    # ç”ŸæˆHTMLæŠ¥å‘Š
    try:
        generate_html_report(results, html, title="æˆªå±æŠ¥å‘Š",
                             template=template)
        logger.info(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html}")
        
        # è‡ªåŠ¨åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æŠ¥å‘Š
        try:
            html_abs_path = Path(html).absolute()
            webbrowser.open(f'file://{html_abs_path}')
            logger.info("å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æŠ¥å‘Š")
        except Exception as e:
            logger.warning(f"è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨å¤±è´¥: {str(e)}")
    except Exception as e:
        logger.error(f"ç”ŸæˆHTMLæŠ¥å‘Šå¤±è´¥: {str(e)}")

    # å‘é€é’‰é’‰é€šçŸ¥
    if dingding_webhook:
        try:
            notification_content = f"""### ğŸ“¸ æˆªå±ä»»åŠ¡å®Œæˆ

**æ‰§è¡Œæ—¶é—´**: {start_time.strftime('%Y-%m-%d %H:%M:%S')}

**æ‰§è¡Œç»“æœ**:
- æ€»æ•°: {total}
- æˆåŠŸ: {success} âœ…
- å¤±è´¥: {failed} âŒ
- è€—æ—¶: {duration:.2f}ç§’

**ä¸»æœºåœ°å€**: {host}

**CSVæ–‡ä»¶**: {csv_file}
"""
            asyncio.run(
                send_dingding_notification(
                    dingding_webhook,
                    "æˆªå±ä»»åŠ¡å®Œæˆ",
                    notification_content
                )
            )
        except Exception as e:
            logger.error(f"å‘é€é’‰é’‰é€šçŸ¥å¤±è´¥: {str(e)}")

    # å¦‚æœæœ‰å¤±è´¥çš„ä»»åŠ¡ï¼Œä»¥éé›¶çŠ¶æ€ç é€€å‡º
    if failed > 0:
        sys.exit(1)


def read_csv_urls(csv_file: str, logger) -> List[Dict]:
    """è¯»å–CSVæ–‡ä»¶ä¸­çš„URLåˆ—è¡¨

    æ”¯æŒçš„åˆ—åï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ï¼š
    - url/URL: URLåœ°å€ï¼ˆå¿…éœ€ï¼‰
    - name/PRODUCT_ID: æˆªå›¾åç§°ï¼ˆå¯é€‰ï¼‰
    """
    urls = []

    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)

            if not reader.fieldnames:
                logger.error("CSVæ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
                return []

            # åˆ›å»ºåˆ—åæ˜ å°„ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            fieldnames_lower = {
                name.lower(): name for name in reader.fieldnames
            }

            # æŸ¥æ‰¾URLåˆ—
            url_column = None
            for possible_name in ['url', 'URL']:
                if possible_name.lower() in fieldnames_lower:
                    url_column = fieldnames_lower[possible_name.lower()]
                    break

            if not url_column:
                logger.error(
                    f"CSVæ–‡ä»¶å¿…é¡»åŒ…å«'url'æˆ–'URL'åˆ—ï¼Œ"
                    f"å½“å‰åˆ—: {', '.join(reader.fieldnames)}"
                )
                return []

            # æŸ¥æ‰¾åç§°åˆ—ï¼ˆä¼˜å…ˆçº§ï¼šname > PRODUCT_IDï¼‰
            name_column = None
            for possible_name in ['name', 'PRODUCT_ID', 'product_id',
                                  'title', 'TITLE']:
                if possible_name.lower() in fieldnames_lower:
                    name_column = fieldnames_lower[possible_name.lower()]
                    break

            logger.info(
                f"ä½¿ç”¨åˆ—: URL='{url_column}', "
                f"NAME='{name_column or '(è‡ªåŠ¨ç”Ÿæˆ)'}'")

            for idx, row in enumerate(reader, 1):
                url = row.get(url_column, '').strip()
                if not url:
                    logger.warning(f"ç¬¬{idx}è¡Œ: URLä¸ºç©ºï¼Œè·³è¿‡")
                    continue

                # è·å–åç§°
                if name_column:
                    name = (row.get(name_column, '').strip() or
                            f'screenshot-{idx}')
                else:
                    name = f'screenshot-{idx}'

                urls.append({
                    'url': url,
                    'name': name,
                    'index': idx
                })

    except Exception as e:
        logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}")
        return []

    return urls


async def run_screenshot_tasks(
    urls: List[Dict],
    host: str,
    output_dir: Path,
    concurrency: int,
    timeout: int,
    width: int,
    height: int,
    logger
) -> List[Dict]:
    """è¿è¡Œæˆªå›¾ä»»åŠ¡"""
    results = []

    async with async_playwright() as p:
        # å¯åŠ¨æµè§ˆå™¨ - æ·»åŠ åçˆ¬è™«å’Œæ€§èƒ½ä¼˜åŒ–å‚æ•°
        try:
            # è½»é‡çº§æµè§ˆå™¨å¯åŠ¨å‚æ•°
            # ï¼ˆé’ˆå¯¹ä½é…ç½®æœåŠ¡å™¨ä¼˜åŒ– + åçˆ¬è™«ï¼‰
            launch_args = [
                '--no-sandbox',
                '--disable-dev-shm-usage',  # é‡è¦ï¼šä½å†…å­˜ç¯å¢ƒ
                '--disable-setuid-sandbox',
                '--disable-gpu',  # é‡è¦ï¼šèŠ‚çœèµ„æº
                '--disable-software-rasterizer',
                '--disable-extensions',
                '--disable-background-networking',  # å‡å°‘åå°ç½‘ç»œè¯·æ±‚
                '--disable-background-timer-throttling',
                '--disable-backgrounding-occluded-windows',
                '--disable-breakpad',
                '--disable-client-side-phishing-detection',
                '--disable-component-update',
                '--disable-default-apps',
                '--disable-domain-reliability',
                '--disable-features=AudioServiceOutOfProcess',
                '--disable-hang-monitor',
                '--disable-ipc-flooding-protection',
                '--disable-notifications',
                '--disable-offer-store-unmasked-wallet-cards',
                '--disable-popup-blocking',
                '--disable-print-preview',
                '--disable-prompt-on-repost',
                '--disable-renderer-backgrounding',
                '--disable-sync',
                '--disable-translate',
                '--metrics-recording-only',
                '--no-first-run',
                '--mute-audio',
                '--safebrowsing-disable-auto-update',
                '--enable-automation',
                '--password-store=basic',
                '--use-mock-keychain',
            ]

            browser = await p.chromium.launch(
                headless=True,
                args=launch_args,
                chromium_sandbox=False,
            )
            logger.info("æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼ˆå·²å¯ç”¨åçˆ¬è™«ä¼˜åŒ–ï¼‰")
        except Exception as e:
            logger.error(f"å¯åŠ¨æµè§ˆå™¨å¤±è´¥: {str(e)}")
            logger.error("è¯·ç¡®ä¿å·²å®‰è£…Playwrightæµè§ˆå™¨: playwright install chromium")
            return []

        try:
            # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘
            semaphore = asyncio.Semaphore(concurrency)

            # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
            tasks = []
            for url_info in urls:
                task = screenshot_single_page(
                    browser=browser,
                    url_info=url_info,
                    host=host,
                    output_dir=output_dir,
                    timeout=timeout,
                    width=width,
                    height=height,
                    semaphore=semaphore,
                    logger=logger
                )
                tasks.append(task)

            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†å¼‚å¸¸ç»“æœ
            processed_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    processed_results.append({
                        'url': urls[i]['url'],
                        'name': urls[i]['name'],
                        'status': 'failed',
                        'error': str(result)
                    })
                else:
                    processed_results.append(result)

            results = processed_results

        finally:
            await browser.close()
            logger.info("æµè§ˆå™¨å·²å…³é—­")

    return results


async def screenshot_single_page(
    browser: Browser,
    url_info: Dict,
    host: str,
    output_dir: Path,
    timeout: int,
    width: int,
    height: int,
    semaphore: asyncio.Semaphore,
    logger
) -> Dict:
    """æˆªå–å•ä¸ªé¡µé¢"""
    url = url_info['url']
    name = url_info['name']
    index = url_info['index']

    async with semaphore:
        # æ„å»ºå®Œæ•´URL
        full_url = build_full_url(url, host)

        logger.info(f"[{index}] å¼€å§‹æˆªå›¾: {full_url}")

        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        safe_name = "".join(
            c for c in name if c.isalnum() or c in (' ', '-', '_')
        ).strip()
        safe_name = safe_name or f'screenshot-{index}'
        filename = f"{safe_name}_{timestamp}.png"
        screenshot_path = output_dir / filename

        page = None
        context = None
        try:
            # ğŸ”¥ åçˆ¬è™«æœºåˆ¶1: éšæœºå»¶è¿Ÿï¼ˆæ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼‰
            delay = random.uniform(1.5, 3.5)
            logger.debug(f"[{index}] éšæœºå»¶è¿Ÿ {delay:.2f} ç§’")
            await asyncio.sleep(delay)

            # ğŸ”¥ åçˆ¬è™«æœºåˆ¶2: è½»é‡çº§ä¸Šä¸‹æ–‡é…ç½® + çœŸå®æµè§ˆå™¨ç‰¹å¾
            # é«˜æ¸…æ™°åº¦è®¾ç½®ï¼šå¯ç”¨è®¾å¤‡åƒç´ æ¯” (device_scale_factor)
            context = await browser.new_context(
                viewport={'width': width, 'height': height},
                device_scale_factor=2,  # 2x DPIï¼Œæé«˜æˆªå›¾æ¸…æ™°åº¦
                user_agent=(
                    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                    'AppleWebKit/537.36 (KHTML, like Gecko) '
                    'Chrome/120.0.0.0 Safari/537.36'
                ),
                locale='en-US',
                ignore_https_errors=True,  # å¿½ç•¥ HTTPS é”™è¯¯
            )

            page = await context.new_page()

            # è®¾ç½®è¶…æ—¶
            page.set_default_navigation_timeout(timeout)
            page.set_default_timeout(timeout)

            # ğŸ”¥ åçˆ¬è™«æœºåˆ¶3: ä½¿ç”¨ domcontentloaded è€Œä¸æ˜¯å®Œå…¨åŠ è½½
            # ï¼ˆæ›´å¿«ï¼Œæ›´åƒçœŸå®æµè§ˆï¼‰
            resp = await page.goto(full_url,
                                   wait_until='domcontentloaded')

            # ğŸ”¥ åçˆ¬è™«æœºåˆ¶4: å°è¯•ç­‰å¾…ç½‘ç»œç©ºé—²ï¼Œä½†ä¸å¼ºåˆ¶
            # ï¼ˆé¿å…è¶…æ—¶ï¼‰
            try:
                await page.wait_for_load_state('networkidle',
                                               timeout=3000)
            except Exception:
                # è¶…æ—¶ä¸å½±å“æˆªå›¾ï¼Œç»§ç»­æ‰§è¡Œ
                logger.debug(f"[{index}] ç½‘ç»œç©ºé—²ç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­æˆªå›¾")
                pass

            # æ£€æŸ¥ HTTP çŠ¶æ€ç 
            if resp is not None and resp.status >= 400:
                error_msg = f"HTTP {resp.status}"
                logger.warning(
                    f"[{index}] HTTP é”™è¯¯: {full_url} - {error_msg}")
                await context.close()
                return {
                    'url': full_url,
                    'name': name,
                    'screenshot_path': '',
                    'status': 'failed',
                    'error': error_msg
                }

            # ğŸ”¥ åçˆ¬è™«æœºåˆ¶5: ä½¿ç”¨ JPEG æ ¼å¼ + é™ä½è´¨é‡ï¼ˆæ›´å¿«ï¼‰
            # ä½†ä¿æŒ PNG æ ¼å¼ä»¥ç¡®ä¿è´¨é‡ï¼ˆæ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
            await page.screenshot(path=str(screenshot_path),
                                  full_page=True)

            logger.info(f"[{index}] æˆªå›¾æˆåŠŸ: {full_url}")

            await context.close()

            return {
                'url': full_url,
                'name': name,
                'screenshot_path': str(screenshot_path),
                'status': 'success',
                'error': ''
            }

        except Exception as e:
            error_msg = str(e)
            logger.error(f"[{index}] æˆªå›¾å¤±è´¥: {full_url} - {error_msg}")

            if context:
                try:
                    await context.close()
                except Exception:
                    pass

            return {
                'url': full_url,
                'name': name,
                'screenshot_path': '',
                'status': 'failed',
                'error': error_msg
            }


def build_full_url(url: str, host: str) -> str:
    """æ„å»ºå®Œæ•´URL

    å¦‚æœURLå·²ç»åŒ…å«åŸŸåï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™ä½¿ç”¨æä¾›çš„host
    """
    url = url.strip()

    # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯å®Œæ•´URL
    parsed = urlparse(url)
    if parsed.scheme and parsed.netloc:
        return url

    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œä¸hostç»„åˆ
    if not url.startswith('/'):
        url = '/' + url

    return urljoin(host, url)
