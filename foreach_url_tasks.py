"""
ForeachURL Celery tasks

ä»»åŠ¡åï¼š
 - tasks.foreach_url_process_job
"""

from __future__ import annotations

import asyncio
import mimetypes
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Optional, Tuple
from urllib.parse import urlparse

from loguru import logger
from playwright.async_api import async_playwright

from app.celery_app import celery_app
from app.config import settings
from app.core.database import supabase


def _now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()


def _safe_part(s: str) -> str:
    s = (s or "").strip()
    if not s:
        return "NA"
    s = s.replace(" ", "_")
    s = re.sub(r"[^a-zA-Z0-9._-]", "_", s)
    s = re.sub(r"_+", "_", s)
    return s[:120] or "NA"


def _make_filename(ptn_no: str, product_id: str) -> str:
    return f"PTN_{_safe_part(ptn_no)}_{_safe_part(product_id)}.jpg"


def _pick_unique_name(base_name: str, used: set[str]) -> str:
    if base_name not in used:
        used.add(base_name)
        return base_name
    stem = base_name[:-4] if base_name.lower().endswith((".png", ".jpg", ".jpeg")) else base_name
    i = 2
    while True:
        candidate = f"{stem}_{i}.jpg"
        if candidate not in used:
            used.add(candidate)
            return candidate
        i += 1


def _classify_error(exc: Exception) -> Tuple[str, str]:
    msg = str(exc)
    low = msg.lower()
    if "timeout" in low:
        return "timeout", msg
    if "net::" in low or "dns" in low or "name not resolved" in low:
        return "network", msg
    return "navigation_error", msg


async def _upload_to_bucket(bucket: str, storage_path: str, local_path: Path) -> str:
    mime_type, _ = mimetypes.guess_type(str(local_path))
    if not mime_type:
        mime_type = "image/png"
    with open(local_path, "rb") as f:
        content = f.read()

    # ä¸Šä¼ ï¼ˆè¦†ç›–ç­–ç•¥ï¼šè‹¥å·²å­˜åœ¨ä¼šæŠ¥é”™ï¼›æˆ‘ä»¬ç”¨å”¯ä¸€æ–‡ä»¶åé¿å…å†²çªï¼‰
    supabase.storage.from_(bucket).upload(
        path=storage_path,
        file=content,
        file_options={"content-type": mime_type},
    )

    return supabase.storage.from_(bucket).get_public_url(storage_path)


@celery_app.task(name="tasks.foreach_url_process_job")
def foreach_url_process_job(job_id: str):
    """
    é¡ºåºå¤„ç†ä¸€ä¸ª jobï¼šéå†æ‰€æœ‰ resultsï¼Œè®¿é—® URL -> è®°å½•çŠ¶æ€ç /é”™è¯¯ -> æˆåŠŸåˆ™æˆªå›¾å¹¶ä¸Šä¼ 
    """
    logger.info(f"ğŸ” ForeachURL job start: {job_id}")

    try:
        supabase.table("foreach_url_jobs").update(
            {"status": "running", "started_at": _now_iso()}
        ).eq("id", job_id).execute()

        # æ‹‰å–å…¨éƒ¨ resultsï¼ˆåªå–å¿…è¦å­—æ®µï¼‰
        # æ³¨æ„ï¼šSupabase å•æ¬¡è¿”å›é™åˆ¶ä¸æ˜ç¡®ï¼Œè¿™é‡Œåˆ†é¡µæ‹‰å–
        all_results: list[dict[str, Any]] = []
        page_size = 1000
        offset = 0
        while True:
            resp = (
                supabase.table("foreach_url_results")
                .select("id,ptn_no,product_id,url,screenshot_url,http_status,error_type,error_message")
                .eq("job_id", job_id)
                .order("created_at", desc=False)
                .range(offset, offset + page_size - 1)
                .execute()
            )
            chunk = resp.data or []
            all_results.extend(chunk)
            if len(chunk) < page_size:
                break
            offset += page_size

        total = len(all_results)
        processed = 0
        success = 0
        failed = 0

        used_names: set[str] = set()
        screenshots_dir = Path("screenshots") / "foreach-url" / job_id
        screenshots_dir.mkdir(parents=True, exist_ok=True)

        bucket = getattr(settings, "FOREACH_URL_SCREENSHOT_BUCKET", "foreach-url-screenshots")

        async def run():
            nonlocal processed, success, failed

            async with async_playwright() as p:
                # è½»é‡çº§æµè§ˆå™¨å¯åŠ¨å‚æ•°ï¼ˆé’ˆå¯¹ä½é…ç½®æœåŠ¡å™¨ä¼˜åŒ–ï¼‰
                launch_args = [
                    '--no-sandbox',
                    '--disable-dev-shm-usage',  # é‡è¦ï¼šä½å†…å­˜ç¯å¢ƒ
                    '--disable-setuid-sandbox',
                    '--disable-gpu',  # é‡è¦ï¼šèŠ‚çœèµ„æº
                    '--disable-software-rasterizer',
                    '--disable-extensions',
                    '--disable-background-networking',  # å‡å°‘åå°ç½‘ç»œè¯·æ±‚
                    '--disable-background-timer-throttling',
                    '--disable-backgrounding-occluded-windows',
                    '--disable-breakpad',
                    '--disable-client-side-phishing-detection',
                    '--disable-component-update',
                    '--disable-default-apps',
                    '--disable-domain-reliability',
                    '--disable-features=AudioServiceOutOfProcess',
                    '--disable-hang-monitor',
                    '--disable-ipc-flooding-protection',
                    '--disable-notifications',
                    '--disable-offer-store-unmasked-wallet-cards',
                    '--disable-popup-blocking',
                    '--disable-print-preview',
                    '--disable-prompt-on-repost',
                    '--disable-renderer-backgrounding',
                    '--disable-sync',
                    '--disable-translate',
                    '--metrics-recording-only',
                    '--no-first-run',
                    '--mute-audio',
                    '--safebrowsing-disable-auto-update',
                    '--enable-automation',
                    '--password-store=basic',
                    '--use-mock-keychain',
                ]
                
                browser = await p.chromium.launch(
                    headless=True,
                    args=launch_args,
                    chromium_sandbox=False,
                )
                
                # è½»é‡çº§ä¸Šä¸‹æ–‡é…ç½®ï¼ˆé™ä½åˆ†è¾¨ç‡ï¼Œå‡å°‘å†…å­˜å ç”¨ï¼‰
                context = await browser.new_context(
                    viewport={"width": 1280, "height": 720},  # é™ä½åˆ†è¾¨ç‡
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                    locale="en-US",
                    ignore_https_errors=True,
                )
                
                page = await context.new_page()
                # è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
                page.set_default_navigation_timeout(getattr(settings, "PLAYWRIGHT_TIMEOUT", 30000))
                page.set_default_timeout(getattr(settings, "PLAYWRIGHT_TIMEOUT", 30000))

                try:
                    for r in all_results:
                        result_id = r["id"]
                        url = r.get("url") or ""
                        ptn_no = r.get("ptn_no") or ""
                        product_id = r.get("product_id") or ""

                        # ğŸ”´ æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²è¢«å–æ¶ˆ
                        job_status_check = supabase.table("foreach_url_jobs").select("status").eq("id", job_id).single().execute()
                        if job_status_check.data and job_status_check.data.get("status") == "cancelled":
                            logger.info(f"âš ï¸ ForeachURL job cancelled by user: {job_id}")
                            return {"job_id": job_id, "message": "ä»»åŠ¡å·²è¢«ç”¨æˆ·å–æ¶ˆ", "cancelled": True}

                        # å¦‚æœå·²ç»å¤„ç†è¿‡ï¼ˆå·²æœ‰æˆªå›¾æˆ–å·²æœ‰é”™è¯¯/çŠ¶æ€ç ï¼‰ï¼Œè·³è¿‡
                        if r.get("screenshot_url") or r.get("http_status") or r.get("error_type") or r.get("error_message"):
                            processed += 1
                            if r.get("screenshot_url"):
                                success += 1
                            else:
                                failed += 1
                            continue

                        http_status: Optional[int] = None
                        error_type: Optional[str] = None
                        error_message: Optional[str] = None
                        screenshot_url: Optional[str] = None
                        screenshot_path: Optional[str] = None

                        try:
                            # åŸºæœ¬ URL æ ¡éªŒ
                            parsed = urlparse(url)
                            if parsed.scheme not in ("http", "https"):
                                raise ValueError(f"Invalid URL scheme: {url}")

                            # é€‚åº¦å»¶è¿Ÿï¼ˆé™ä½æœåŠ¡å™¨å‹åŠ›ï¼‰
                            import random
                            await asyncio.sleep(random.uniform(2.0, 4.0))
                            
                            # ç›´æ¥è®¿é—®é¡µé¢ï¼Œä¸é¢å¤–è®¾ç½®headersï¼ˆé¿å…å´©æºƒï¼‰
                            resp = await page.goto(url, wait_until="domcontentloaded")
                            
                            # ç®€çŸ­ç­‰å¾…è®©é¡µé¢ç¨³å®š
                            try:
                                await page.wait_for_load_state("networkidle", timeout=3000)
                            except Exception:
                                pass  # è¶…æ—¶ä¸å½±å“æˆªå›¾
                            
                            if resp is not None:
                                http_status = resp.status
                            else:
                                http_status = None

                            if http_status is not None and http_status >= 400:
                                error_type = "http_error"
                                error_message = f"HTTP {http_status}"
                            else:
                                base_name = _make_filename(ptn_no, product_id)
                                filename = _pick_unique_name(base_name, used_names)
                                local_path = screenshots_dir / filename

                                # è§†å£æˆªå›¾ï¼ˆé™ä½è´¨é‡ä»¥èŠ‚çœèµ„æºï¼‰
                                await page.screenshot(
                                    path=str(local_path), 
                                    full_page=False,
                                    type='jpeg',  # ä½¿ç”¨JPEGæ ¼å¼ï¼Œæ–‡ä»¶æ›´å°
                                    quality=80    # é™ä½è´¨é‡ä»¥èŠ‚çœå†…å­˜
                                )

                                storage_path = f"foreach-url/{job_id}/{filename}"
                                screenshot_path = storage_path
                                screenshot_url = await _upload_to_bucket(bucket, storage_path, local_path)

                        except Exception as exc:
                            et, em = _classify_error(exc)
                            error_type = et
                            error_message = em

                        # å†™å› result
                        supabase.table("foreach_url_results").update(
                            {
                                "http_status": http_status,
                                "error_type": error_type,
                                "error_message": error_message,
                                "screenshot_url": screenshot_url,
                                "screenshot_path": screenshot_path,
                            }
                        ).eq("id", result_id).execute()

                        processed += 1
                        if screenshot_url:
                            success += 1
                        else:
                            failed += 1

                        # æ›´æ–° job è¿›åº¦ï¼ˆå•ä»»åŠ¡ä¸²è¡Œæ‰§è¡Œï¼Œä¸å­˜åœ¨å¹¶å‘å†™å†²çªï¼‰
                        supabase.table("foreach_url_jobs").update(
                            {
                                "total": total,
                                "processed": processed,
                                "success": success,
                                "failed": failed,
                                "status": "running",
                            }
                        ).eq("id", job_id).execute()

                finally:
                    try:
                        await page.close()
                        await context.close()
                        await browser.close()
                    except Exception:
                        pass

        asyncio.run(run())

        supabase.table("foreach_url_jobs").update(
            {
                "total": total,
                "processed": processed,
                "success": success,
                "failed": failed,
                "status": "success",
                "finished_at": _now_iso(),
            }
        ).eq("id", job_id).execute()

        logger.info(f"âœ… ForeachURL job done: {job_id}, total={total}, success={success}, failed={failed}")

        return {"job_id": job_id, "total": total, "success": success, "failed": failed}

    except Exception as e:
        logger.error(f"âŒ ForeachURL job failed: {job_id}: {e}")
        try:
            supabase.table("foreach_url_jobs").update(
                {"status": "failed", "finished_at": _now_iso()}
            ).eq("id", job_id).execute()
        except Exception:
            pass
        raise


