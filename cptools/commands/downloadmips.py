"""ä¸‹è½½äº§å“ä¸»å›¾å‘½ä»¤å®ç°"""
import click
import asyncio
import csv
import random
import shutil
import webbrowser
from pathlib import Path
from datetime import datetime
from typing import List, Dict
import sys

from playwright.async_api import async_playwright, Browser
from cptools.utils.logger import setup_logger
from cptools.utils.downloadmips_report import (
    generate_downloadmips_html_report
)
from cptools.utils.dingding import send_dingding_notification


@click.command()
@click.option(
    '--host', '-h', required=True,
    help='ä¸»æœºåœ°å€ï¼ˆå¦‚: https://www.cafepress.comï¼‰')
@click.option(
    '--csv', 'csv_file', required=True, type=click.Path(exists=True),
    help='CSVæ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«äº§å“ç¼–å·åˆ—è¡¨ï¼ˆproduct_noåˆ—ï¼‰')
@click.option(
    '--output', '-o', default='./mips',
    help='å›¾ç‰‡ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ï¼š./mipsï¼‰')
@click.option(
    '--log', '-l', default='',
    help='æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼š./logs/downloadmips_YYYYMMDD_HHMMSS.logï¼‰')
@click.option(
    '--html', default='./downloadmips_result.html',
    help='HTMLæŠ¥å‘Šè¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤ï¼š./downloadmips_result.htmlï¼‰')
@click.option(
    '--concurrency', '-c', default=3, type=int,
    help='å¹¶å‘æ•°é‡ï¼ˆé»˜è®¤ï¼š3ï¼Œå»ºè®®ä¸è¦å¤ªå¤§ä»¥é¿å…è¢«å°ï¼‰')
@click.option(
    '--dingding-webhook',
    default='https://oapi.dingtalk.com/robot/send?access_token='
            'ce631c399761d21df6460018238a6fd22c237e3feb7021c580f34967c9a6e951',
    help='é’‰é’‰æœºå™¨äººWebhook URLï¼ˆé»˜è®¤å·²é…ç½®ï¼‰')
@click.option(
    '--dingding-secret',
    default='SECdc9d0205aebf46618039a4bf770cb69ed87173bc7270cead292136c1'
            '4287708f',
    help='é’‰é’‰æœºå™¨äººç­¾åå¯†é’¥ï¼ˆé»˜è®¤å·²é…ç½®ï¼‰')
@click.option(
    '--no-dingding', is_flag=True, default=False,
    help='ç¦ç”¨é’‰é’‰é€šçŸ¥ï¼ˆè°ƒè¯•æ—¶ä½¿ç”¨ï¼‰')
@click.option(
    '--timeout', default=30000, type=int,
    help='é¡µé¢åŠ è½½è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼Œé»˜è®¤ï¼š30000ï¼‰')
def downloadmips(host, csv_file, output, log, html, concurrency,
                 dingding_webhook, dingding_secret, no_dingding, timeout):
    """äº§å“ä¸»å›¾ä¸‹è½½å·¥å…·

    ä»CSVæ–‡ä»¶è¯»å–äº§å“ç¼–å·åˆ—è¡¨å¹¶ä¸‹è½½ä¸»å›¾ã€‚CSVæ–‡ä»¶åº”åŒ…å«ä»¥ä¸‹åˆ—ï¼š

    \b
    - product_no: äº§å“ç¼–å·ï¼ˆå¿…éœ€ï¼‰

    äº§å“URLæ ¼å¼: {host}/+,{product_no}

    æ”¯æŒçš„åœ°åŒºï¼š

    \b
    - US: https://www.cafepress.com
    - AU: https://www.cafepress.com.au
    - UK: https://www.cafepress.co.uk
    - CA: https://www.cafepress.ca

    ç¤ºä¾‹ï¼š

    \b
    cptools downloadmips --host https://www.cafepress.com \\
        --csv products.csv

    \b
    cptools downloadmips -h https://www.cafepress.com.au \\
        --csv products.csv -c 5
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥å¿—æ–‡ä»¶ï¼Œè‡ªåŠ¨ç”ŸæˆåŸºäºæ—¶é—´æˆ³çš„æ–‡ä»¶å
    if not log:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        log = f'./logs/downloadmips_{timestamp}.log'
        # ç¡®ä¿ logs ç›®å½•å­˜åœ¨
        Path('./logs').mkdir(parents=True, exist_ok=True)

    # è®¾ç½®æ—¥å¿—
    logger = setup_logger(log)

    logger.info("=" * 80)
    logger.info("å¼€å§‹æ‰§è¡Œäº§å“ä¸»å›¾ä¸‹è½½ä»»åŠ¡")
    logger.info(f"ä¸»æœºåœ°å€: {host}")
    logger.info(f"CSVæ–‡ä»¶: {csv_file}")
    logger.info(f"è¾“å‡ºç›®å½•: {output}")
    logger.info(f"å¹¶å‘æ•°: {concurrency}")
    logger.info(f"è¶…æ—¶æ—¶é—´: {timeout}ms")
    logger.info("=" * 80)

    # æ£€æŸ¥Playwrightæ˜¯å¦å·²å®‰è£…
    try:
        from playwright.async_api import async_playwright  # noqa: F401
    except ImportError:
        logger.error("Playwrightæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install playwright")
        logger.error("ç„¶åè¿è¡Œ: playwright install chromium")
        sys.exit(1)

    # è¯»å–CSVæ–‡ä»¶
    products = read_csv_products(csv_file, logger)
    if not products:
        logger.error("CSVæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„Product No")
        sys.exit(1)

    logger.info(f"ä»CSVæ–‡ä»¶ä¸­è¯»å–åˆ° {len(products)} ä¸ªProduct No")

    # æ¸…ç†æ—§æ–‡ä»¶
    output_dir = Path(output)
    html_path = Path(html)

    # åˆ é™¤æ—§çš„å›¾ç‰‡ç›®å½•
    if output_dir.exists():
        logger.info(f"åˆ é™¤æ—§çš„Product Noç›®å½•: {output_dir}")
        shutil.rmtree(output_dir)

    # åˆ é™¤æ—§çš„HTMLæŠ¥å‘Š
    if html_path.exists():
        logger.info(f"åˆ é™¤æ—§çš„HTMLæŠ¥å‘Š: {html_path}")
        html_path.unlink()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"åˆ›å»ºæ–°çš„Product Noç›®å½•: {output_dir}")

    # æ‰§è¡Œä¸‹è½½ä»»åŠ¡
    start_time = datetime.now()
    results = asyncio.run(
        run_download_tasks(
            products=products,
            host=host,
            output_dir=output_dir,
            concurrency=concurrency,
            timeout=timeout,
            logger=logger
        )
    )
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()

    # ç»Ÿè®¡ç»“æœ
    total = len(results)
    success = sum(1 for r in results if r.get('status') == 'success')
    failed = total - success
    total_images = sum(r.get('image_count', 0) for r in results)

    logger.info("=" * 80)
    logger.info("Product MIPs Download Task Completed")
    logger.info("=" * 80)
    logger.info(f"Total Product Count: {total}")
    logger.info(f"Success: {success}")
    logger.info(f"Failed: {failed}")
    logger.info(f"Downloaded Image Count: {total_images}")
    logger.info(f"Duration: {duration:.2f} seconds")
    logger.info("=" * 80)

    # ç”ŸæˆHTMLæŠ¥å‘Š
    try:
        generate_downloadmips_html_report(
            results, html, title="Product MIPs Download Report")
        logger.info(f"HTML Report Generated: {html}")

        # è‡ªåŠ¨åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æŠ¥å‘Š
        try:
            html_abs_path = Path(html).absolute()
            webbrowser.open(f'file://{html_abs_path}')
            logger.info("Report Opened in Browser")
        except Exception as e:
            logger.warning(f"Failed to open browser: {str(e)}")
    except Exception as e:
        logger.error(f"Failed to generate HTML report: {str(e)}")

    # å‘é€é’‰é’‰é€šçŸ¥
    if dingding_webhook and not no_dingding:
        try:
            notification_content = f"""### ğŸ–¼ï¸ Product MIPs Download Completed

**Time**: {start_time.strftime('%Y-%m-%d %H:%M:%S')}

**Results**: Total {total} | Success {success}âœ… | Failed {failed}âŒ

**Images**: {total_images} downloaded in {duration:.2f}s

**File**: `{csv_file}`
"""
            asyncio.run(
                send_dingding_notification(
                    dingding_webhook,
                    "Product MIPs Download Task Completed",
                    notification_content,
                    secret=dingding_secret
                )
            )
            logger.info("Dingding Notification Sent Successfully")
        except Exception as e:
            logger.error(f"Failed to send Dingding notification: {str(e)}")
    elif no_dingding:
        logger.info("Dingding notification disabled (--no-dingding)")

    # å¦‚æœæœ‰å¤±è´¥çš„ä»»åŠ¡ï¼Œä»¥éé›¶çŠ¶æ€ç é€€å‡º
    if failed > 0:
        sys.exit(1)


def read_csv_products(csv_file: str, logger) -> List[Dict]:
    """Read the list of Product No from the CSV file

    æ”¯æŒçš„åˆ—åï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ï¼š
    - product_no/PRODUCT_NO: Product No (Required)
    """
    products = []

    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)

            if not reader.fieldnames:
                logger.error("CSV file is empty or format error")
                return []

            # åˆ›å»ºåˆ—åæ˜ å°„ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            fieldnames_lower = {
                name.lower(): name for name in reader.fieldnames
            }

            # æŸ¥æ‰¾äº§å“ç¼–å·åˆ—
            product_no_column = None
            for possible_name in ['product_no', 'PRODUCT_NO', 'productno',
                                  'product_id', 'PRODUCT_ID']:
                if possible_name.lower() in fieldnames_lower:
                    product_no_column = (
                        fieldnames_lower[possible_name.lower()]
                    )
                    break

            if not product_no_column:
                logger.error(
                    f"CSV file must contain 'product_no' or "
                    f"'PRODUCT_NO' column, "
                    f"Current columns: {', '.join(reader.fieldnames)}"
                )
                return []

            logger.info(f"Using column: PRODUCT_NO='{product_no_column}'")

            for idx, row in enumerate(reader, 1):
                product_no = row.get(product_no_column, '').strip()
                if not product_no:
                    logger.warning(f"Row {idx}: Product No is empty, skipping")
                    continue

                products.append({
                    'product_no': product_no,
                    'index': idx
                })

    except Exception as e:
        logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}")
        return []

    return products


async def run_download_tasks(
    products: List[Dict],
    host: str,
    output_dir: Path,
    concurrency: int,
    timeout: int,
    logger
) -> List[Dict]:
    """è¿è¡Œä¸‹è½½ä»»åŠ¡"""
    results = []

    async with async_playwright() as p:
        # å¯åŠ¨æµè§ˆå™¨
        try:
            launch_args = [
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-setuid-sandbox',
                '--disable-gpu',
                '--disable-software-rasterizer',
                '--disable-extensions',
                '--disable-background-networking',
                '--disable-background-timer-throttling',
                '--disable-backgrounding-occluded-windows',
                '--disable-breakpad',
                '--disable-client-side-phishing-detection',
                '--disable-component-update',
                '--disable-default-apps',
                '--disable-domain-reliability',
                '--disable-features=AudioServiceOutOfProcess',
                '--disable-hang-monitor',
                '--disable-ipc-flooding-protection',
                '--disable-notifications',
                '--disable-offer-store-unmasked-wallet-cards',
                '--disable-popup-blocking',
                '--disable-print-preview',
                '--disable-prompt-on-repost',
                '--disable-renderer-backgrounding',
                '--disable-sync',
                '--disable-translate',
                '--metrics-recording-only',
                '--no-first-run',
                '--mute-audio',
                '--safebrowsing-disable-auto-update',
                '--enable-automation',
                '--password-store=basic',
                '--use-mock-keychain',
            ]

            browser = await p.chromium.launch(
                headless=True,
                args=launch_args,
                chromium_sandbox=False,
            )
            logger.info("æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
        except Exception as e:
            logger.error(f"å¯åŠ¨æµè§ˆå™¨å¤±è´¥: {str(e)}")
            logger.error(
                "è¯·ç¡®ä¿å·²å®‰è£…Playwrightæµè§ˆå™¨: playwright install chromium"
            )
            return []

        try:
            # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘
            semaphore = asyncio.Semaphore(concurrency)

            # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
            tasks = []
            for product in products:
                task = download_single_product(
                    browser=browser,
                    product=product,
                    host=host,
                    output_dir=output_dir,
                    timeout=timeout,
                    semaphore=semaphore,
                    logger=logger
                )
                tasks.append(task)

            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†å¼‚å¸¸ç»“æœ
            processed_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    product_no = products[i]['product_no']
                    processed_results.append({
                        'product_no': product_no,
                        'url': (
                            f"{host}/+,{product_no}"
                        ),
                        'status': 'failed',
                        'error': str(result),
                        'image_count': 0,
                        'images': []
                    })
                else:
                    processed_results.append(result)

            results = processed_results

        finally:
            await browser.close()
            logger.info("æµè§ˆå™¨å·²å…³é—­")

    return results


async def download_single_product(
    browser: Browser,
    product: Dict,
    host: str,
    output_dir: Path,
    timeout: int,
    semaphore: asyncio.Semaphore,
    logger
) -> Dict:
    """ä¸‹è½½å•ä¸ªäº§å“çš„ä¸»å›¾"""
    product_no = product['product_no']
    index = product['index']
    url = f"{host}/+,{product_no}"

    async with semaphore:
        logger.info(f"[{index}] å¼€å§‹å¤„ç†äº§å“: {product_no}")

        # åˆ›å»ºäº§å“æ–‡ä»¶å¤¹
        product_dir = output_dir / product_no
        product_dir.mkdir(parents=True, exist_ok=True)

        page = None
        context = None
        try:
            # éšæœºå»¶è¿Ÿï¼ˆæ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼‰
            delay = random.uniform(2.0, 4.0)
            logger.debug(f"[{index}] éšæœºå»¶è¿Ÿ {delay:.2f} ç§’")
            await asyncio.sleep(delay)

            # åˆ›å»ºä¸Šä¸‹æ–‡
            context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent=(
                    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                    'AppleWebKit/537.36 (KHTML, like Gecko) '
                    'Chrome/120.0.0.0 Safari/537.36'
                ),
                locale='en-US',
                ignore_https_errors=True,
            )

            page = await context.new_page()

            # è®¾ç½®è¶…æ—¶
            page.set_default_navigation_timeout(timeout)
            page.set_default_timeout(timeout)

            # è®¿é—®é¡µé¢
            logger.info(f"[{index}] è®¿é—®é¡µé¢: {url}")
            resp = await page.goto(url, wait_until='domcontentloaded')

            # æ£€æŸ¥HTTPçŠ¶æ€ç 
            if resp is None or resp.status >= 400:
                error_msg = (
                    f"HTTP {resp.status if resp else 'No Response'}"
                )
                logger.error(f"[{index}] è®¿é—®å¤±è´¥: {url} - {error_msg}")
                await context.close()
                return {
                    'product_no': product_no,
                    'url': url,
                    'status': 'failed',
                    'error': error_msg,
                    'image_count': 0,
                    'images': []
                }

            # ç­‰å¾…é¡µé¢åŠ è½½
            try:
                await page.wait_for_load_state('networkidle', timeout=5000)
            except Exception:
                logger.debug(f"[{index}] ç½‘ç»œç©ºé—²ç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­å¤„ç†")
                pass

            # æŸ¥æ‰¾æ‰€æœ‰ class="stackable-image-container" çš„ div ä¸‹çš„å›¾ç‰‡
            logger.info(f"[{index}] æŸ¥æ‰¾äº§å“ä¸»å›¾...")
            images = await page.query_selector_all(
                '.stackable-image-container img'
            )

            if not images:
                error_msg = (
                    "æœªæ‰¾åˆ°äº§å“ä¸»å›¾ (class='stackable-image-container')"
                )
                logger.warning(f"[{index}] {error_msg}")
                await context.close()
                return {
                    'product_no': product_no,
                    'url': url,
                    'status': 'failed',
                    'error': error_msg,
                    'image_count': 0,
                    'images': []
                }

            logger.info(f"[{index}] æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡")

            # ä¸‹è½½å›¾ç‰‡
            downloaded_images = []
            for img_idx, img in enumerate(images, 1):
                try:
                    # è·å–å›¾ç‰‡URL
                    img_url = await img.get_attribute('src')
                    if not img_url:
                        logger.warning(
                            f"[{index}] å›¾ç‰‡ {img_idx} æ²¡æœ‰srcå±æ€§ï¼Œè·³è¿‡"
                        )
                        continue

                    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬ä¸ºç»å¯¹è·¯å¾„
                    if img_url.startswith('//'):
                        img_url = 'https:' + img_url
                    elif img_url.startswith('/'):
                        # ä½¿ç”¨ host æ„å»ºå®Œæ•´ URL
                        img_url = host.rstrip('/') + img_url

                    # è·å–æ–‡ä»¶æ‰©å±•å
                    ext = '.jpg'
                    if '.png' in img_url.lower():
                        ext = '.png'
                    elif '.gif' in img_url.lower():
                        ext = '.gif'
                    elif '.webp' in img_url.lower():
                        ext = '.webp'

                    # ç”Ÿæˆæ–‡ä»¶å
                    img_filename = f"{product_no}_{img_idx:02d}{ext}"
                    img_path = product_dir / img_filename

                    # ä¸‹è½½å›¾ç‰‡
                    logger.debug(
                        f"[{index}] ä¸‹è½½å›¾ç‰‡ {img_idx}: {img_url}"
                    )

                    # ä½¿ç”¨ CDP ä¸‹è½½å›¾ç‰‡ï¼ˆæ›´å¯é ï¼‰
                    img_data = await page.evaluate(f'''
                        async () => {{
                            const response = await fetch("{img_url}");
                            const blob = await response.blob();
                            const reader = new FileReader();
                            return new Promise((resolve) => {{
                                reader.onloadend = () => {{
                                    resolve(reader.result);
                                }};
                                reader.readAsDataURL(blob);
                            }});
                        }}
                    ''')

                    # è§£æ base64 æ•°æ®
                    if img_data and img_data.startswith('data:'):
                        import base64
                        base64_data = img_data.split(',')[1]
                        img_bytes = base64.b64decode(base64_data)

                        # ä¿å­˜å›¾ç‰‡
                        with open(img_path, 'wb') as f:
                            f.write(img_bytes)

                        logger.info(
                            f"[{index}] å›¾ç‰‡ {img_idx} "
                            f"ä¸‹è½½æˆåŠŸ: {img_filename}"
                        )
                        downloaded_images.append({
                            'filename': img_filename,
                            'path': str(img_path),
                            'url': img_url
                        })
                    else:
                        logger.warning(
                            f"[{index}] å›¾ç‰‡ {img_idx} "
                            f"ä¸‹è½½å¤±è´¥: æ— æ•ˆçš„æ•°æ®"
                        )

                except Exception as e:
                    logger.error(
                        f"[{index}] å›¾ç‰‡ {img_idx} ä¸‹è½½å¤±è´¥: {str(e)}"
                    )
                    continue

            await context.close()

            if downloaded_images:
                logger.info(
                    f"[{index}] äº§å“ {product_no} å¤„ç†å®Œæˆï¼Œ"
                    f"ä¸‹è½½äº† {len(downloaded_images)} å¼ å›¾ç‰‡"
                )
                return {
                    'product_no': product_no,
                    'url': url,
                    'status': 'success',
                    'error': '',
                    'image_count': len(downloaded_images),
                    'images': downloaded_images
                }
            else:
                error_msg = "æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å¤±è´¥"
                logger.warning(f"[{index}] {error_msg}")
                return {
                    'product_no': product_no,
                    'url': url,
                    'status': 'failed',
                    'error': error_msg,
                    'image_count': 0,
                    'images': []
                }

        except Exception as e:
            error_msg = str(e)
            logger.error(
                f"[{index}] å¤„ç†å¤±è´¥: {product_no} - {error_msg}"
            )

            if context:
                try:
                    await context.close()
                except Exception:
                    pass

            return {
                'product_no': product_no,
                'url': url,
                'status': 'failed',
                'error': error_msg,
                'image_count': 0,
                'images': []
            }
